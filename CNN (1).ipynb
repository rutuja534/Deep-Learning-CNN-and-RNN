{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSZtvxWvPZvx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"Loading 'svhn_cropped' dataset from TFDS...\")\n",
        "\n",
        "# Load the dataset\n",
        "(raw_train, raw_test), metadata = tfds.load(\n",
        "    'svhn_cropped',\n",
        "    split=['train', 'test'],  # We'll split the train set manually later\n",
        "    with_info=True,\n",
        "    as_supervised=True,  # Loads as (image, label) tuples\n",
        ")\n",
        "\n",
        "print(\"Dataset loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B9y6J-eRtcs"
      },
      "outputs": [],
      "source": [
        "# Get the class names from metadata\n",
        "class_names = metadata.features['label'].names\n",
        "print(\"Class names:\", class_names)\n",
        "\n",
        "# Get the number of examples\n",
        "num_train = metadata.splits['train'].num_examples\n",
        "num_test = metadata.splits['test'].num_examples\n",
        "\n",
        "print(f\"Number of training examples: {num_train}\")\n",
        "print(f\"Number of testing examples: {num_test}\")\n",
        "\n",
        "# Check an example image shape\n",
        "for image, label in raw_train.take(1):\n",
        "    print(f\"\\nImage shape: {image.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY1gAyXQRvQ4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "# Take 9 examples from the training set\n",
        "for i, (image, label) in enumerate(raw_train.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    # These are color, so we don't need cmap='gray'\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Label: {class_names[label]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qiasz7vcR5V4"
      },
      "outputs": [],
      "source": [
        "def preprocess(image, label):\n",
        "    # Cast the image to float32\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    # Normalize the pixel values to [0, 1]\n",
        "    image = image / 255.0\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdJj5T53R_pm"
      },
      "outputs": [],
      "source": [
        "# This dictionary will hold our final datasets\n",
        "datasets = {}\n",
        "\n",
        "# Get the total number of training examples\n",
        "num_train = metadata.splits['train'].num_examples\n",
        "\n",
        "# Calculate 10% of the training data for validation\n",
        "num_validation = int(0.1 * num_train)\n",
        "\n",
        "# Create a new validation set (first 10% of train data)\n",
        "val_set = raw_train.take(num_validation)\n",
        "\n",
        "# Create a new training set (the remaining 90%)\n",
        "train_set = raw_train.skip(num_validation)\n",
        "\n",
        "# Now, apply preprocessing to all three splits\n",
        "datasets['train'] = train_set.map(preprocess)\n",
        "datasets['val'] = val_set.map(preprocess)\n",
        "datasets['test'] = raw_test.map(preprocess)\n",
        "\n",
        "# Let's check the new counts\n",
        "print(f\"Original training examples: {num_train}\")\n",
        "print(f\"New validation examples: {num_validation}\")\n",
        "print(f\"New training examples: {num_train - num_validation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxGU9McUSCzy"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    # Shuffle the training data\n",
        "    if split == 'train':\n",
        "        datasets[split] = datasets[split].shuffle(1000)\n",
        "\n",
        "    datasets[split] = datasets[split].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"All datasets are preprocessed, batched, and ready.\")\n",
        "print(\"Example of a batch (shape):\")\n",
        "for images, labels in datasets['train'].take(1):\n",
        "    print(f\" - Images batch shape: {images.shape}\")\n",
        "    print(f\" - Labels batch shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jZKaeTeSF_r"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Input layer specifies the shape of our color images\n",
        "    tf.keras.layers.Input(shape=(32, 32, 3)),\n",
        "\n",
        "    # First convolution block\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    # Second convolution block\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    # Third convolution block (added one more for a deeper model)\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    # Flatten the 3D feature maps into a 1D vector\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Dense (fully connected) layers\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Output layer\n",
        "    # 10 units for 10 classes (digits 0-9)\n",
        "    # 'softmax' activation to get probabilities for each class\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG2Spfa0SQ_z"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Model compiled.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9rWR5GGtSTko"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "history = model.fit(\n",
        "    datasets['train'],\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=datasets['val']\n",
        ")\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating on test data...\")\n",
        "loss, accuracy = model.evaluate(datasets['test'])\n",
        "\n",
        "print(f\"\\nTest Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "jfoBdAXsfq5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}