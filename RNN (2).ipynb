{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyCPill7Fwfq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "print(\"Loading 'ag_news_subset' dataset...\")\n",
        "\n",
        "# Load the dataset\n",
        "(raw_train, raw_test), metadata = tfds.load(\n",
        "    'ag_news_subset',\n",
        "    split=['train', 'test'],\n",
        "    with_info=True,\n",
        "    as_supervised=True  # Loads as (description_text, label)\n",
        ")\n",
        "\n",
        "print(\"Dataset loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djnB_wDlF1_S"
      },
      "outputs": [],
      "source": [
        "# Get the class names from metadata\n",
        "class_names = metadata.features['label'].names\n",
        "print(\"Class names:\", class_names)\n",
        "# You should see: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
        "\n",
        "print(\"\\nHere's an example article:\")\n",
        "for review, label in raw_train.take(1):\n",
        "    review_text = review.numpy().decode('utf-8')\n",
        "    review_label = class_names[label.numpy()]\n",
        "\n",
        "    print(f\"LABEL: {review_label}\")\n",
        "    print(f\"ARTICLE: {review_text[:500]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWBhjO7MF8OM"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "\n",
        "# Create the vectorization layer\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=MAX_SEQUENCE_LENGTH\n",
        ")\n",
        "\n",
        "# Adapt the layer to the training text\n",
        "print(\"Building the vocabulary...\")\n",
        "train_text = raw_train.map(lambda text, label: text)\n",
        "vectorize_layer.adapt(train_text)\n",
        "print(\"Vocabulary built.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBG4STPjJL1t"
      },
      "outputs": [],
      "source": [
        "# This dictionary will hold our final datasets\n",
        "datasets = {}\n",
        "\n",
        "# --- Create a validation split (20% of train data) ---\n",
        "num_train = metadata.splits['train'].num_examples\n",
        "num_val = int(num_train * 0.2)  # 20% for validation\n",
        "\n",
        "val_set = raw_train.take(num_val)\n",
        "train_set = raw_train.skip(num_val)\n",
        "\n",
        "# --- Create the preprocessing function ---\n",
        "def vectorize_text(text, label):\n",
        "    text = vectorize_layer(text)\n",
        "    return text, label\n",
        "\n",
        "# --- Apply the function and batch the datasets ---\n",
        "datasets['train'] = train_set.map(vectorize_text).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "datasets['val'] = val_set.map(vectorize_text).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "datasets['test'] = raw_test.map(vectorize_text).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"All datasets are vectorized and batched.\")\n",
        "print(f\"New training set size: {num_train - num_val}\")\n",
        "print(f\"New validation set size: {num_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeLHwedWKyAz"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 64\n",
        "LSTM_UNITS = 64\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    # 1. The Embedding layer\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n",
        "\n",
        "    # 2. The LSTM layer\n",
        "    tf.keras.layers.LSTM(LSTM_UNITS),\n",
        "\n",
        "    # 3. The classification layers\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # --- KEY CHANGE HERE ---\n",
        "    # Final output layer\n",
        "    # 4 units (one for each class)\n",
        "    # 'softmax' activation for a probability distribution\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft2I4_aYKzv8"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    # --- KEY CHANGE HERE ---\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Model compiled.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3e_CobXK4Z8"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "history = model.fit(\n",
        "    datasets['train'],\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=datasets['val']\n",
        ")\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating on test data...\")\n",
        "loss, accuracy = model.evaluate(datasets['test'])\n",
        "\n",
        "print(f\"\\nTest Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "Qixxhg8K34Vu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}